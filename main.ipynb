{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "from flask import Flask, request, jsonify, render_template, flash, redirect\n",
    "from werkzeug.utils import secure_filename\n",
    "\n",
    "from transformers import ViTImageProcessor, ViTModel, AutoImageProcessor, AutoModelForImageClassification,  AutoModelForCausalLM, AutoTokenizer\n",
    "from PIL import Image\n",
    "import requests\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:01<00:00,  1.05it/s]\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" # the device to load the model onto\n",
    "\n",
    "model_nlp = AutoModelForCausalLM.from_pretrained(\"stabilityai/stable-code-instruct-3b\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"stabilityai/stable-code-instruct-3b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration. Please open a PR/issue to update `preprocessor_config.json` to use `image_processor_type` instead of `feature_extractor_type`. This warning will be removed in v4.40.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# processor = ViTImageProcessor.from_pretrained('nateraw/food')\n",
    "image_processor = AutoImageProcessor.from_pretrained('nateraw/food')\n",
    "# model = ViTModel.from_pretrained('nateraw/food')\n",
    "model_vision = AutoModelForImageClassification.from_pretrained('nateraw/food')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_k_pred_labels(im, k=3):\n",
    "\n",
    "    inputs = image_processor(im, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        logits = model_vision(**inputs).logits\n",
    "    # Get indices of the top two predicted labels\n",
    "    top_k_values, top_k_indices = logits.topk(k, dim=-1)\n",
    "\n",
    "    # Extract the indices as Python scalars\n",
    "    predicted_labels = top_k_indices.tolist()\n",
    "\n",
    "    predicted_labels_with_labels = [[model_vision.config.id2label[label] for label in labels] for labels in predicted_labels]\n",
    "\n",
    "    return predicted_labels_with_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pizza', 'bruschetta', 'garlic_bread']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TESTING VIT \n",
    "filename = \"Test/pizza_slice.jpg\"\n",
    "with Image.open(filename) as image:\n",
    "    image.load()\n",
    "predicted_labels_with_labels = get_top_k_pred_labels(image)\n",
    "predicted_labels_with_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nlp_op_old(messages):\n",
    "\n",
    "    encodeds = tokenizer.apply_chat_template(messages, return_tensors=\"pt\")\n",
    "\n",
    "    model_inputs = encodeds.to(device)\n",
    "    model_nlp.to(device)\n",
    "\n",
    "    generated_ids = model_nlp.generate(model_inputs, max_new_tokens=1000, do_sample=True)\n",
    "    decoded = tokenizer.batch_decode(generated_ids)\n",
    "    print(decoded[0])\n",
    "    return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nlp_op(messages):\n",
    "    prompt = tokenizer.apply_chat_template(messages, add_generation_prompt=True, tokenize=False)\n",
    "    inputs = tokenizer([prompt], return_tensors=\"pt\").to(model_nlp.device)\n",
    "\n",
    "    tokens = model_nlp.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=1024,\n",
    "        temperature=0.5,\n",
    "        top_p=0.95,\n",
    "        top_k=100,\n",
    "        do_sample=True,\n",
    "        use_cache=True\n",
    "    )\n",
    "\n",
    "    output = tokenizer.batch_decode(tokens[:, inputs.input_ids.shape[-1]:], skip_special_tokens=False)[0]\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_template = [\n",
    "       {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are a helpful and polite assistant for diabetes patients\",\n",
    "    }] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Pizza is a delicious and convenient food choice for many people, including those with diabetes. The key thing to remember when eating pizza is to monitor portions and make sure to include healthy sources of protein and complex carbohydrates. Be aware that some toppings, such as fried dough or tomato sauce, may be high in fat and sugars and could increase your risk of developing diabetes. It's best to consult with your doctor before eating any food to ensure you are getting the right nutrition for your health.<|im_end|>\\n<|endoftext|>\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TESTING NLP Model\n",
    "\n",
    "test_msg = message_template + [{\"role\": \"user\", \"content\": \"Is pizza good for me as a diabetes patient\"}]\n",
    "    \n",
    "get_nlp_op(test_msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = Flask(__name__)\n",
    "UPLOAD_FOLDER = 'uploads'\n",
    "ALLOWED_EXTENSIONS = set(['jpg', 'jpeg'])\n",
    "\n",
    "def allowed_file(filename):     \n",
    "    return '.' in filename and filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS\n",
    "\n",
    "app.config['UPLOAD_FOLDER'] = UPLOAD_FOLDER\n",
    "\n",
    "@app.route(\"/\")\n",
    "def showHomePage():\n",
    "      # response from the server\n",
    "    return render_template('index.html')\n",
    "\n",
    "@app.route(\"/food_detector\", methods = [\"GET\", \"POST\"])\n",
    "def upload_file():\n",
    "    if request.method == 'POST':\n",
    "        # check if the post request has the file part\n",
    "        if 'file' not in request.files:\n",
    "            print('No file part')\n",
    "            return redirect(request.url)\n",
    "        file = request.files['file']\n",
    "\n",
    "        if file.filename == '':\n",
    "            print('No selected file')\n",
    "            return redirect(request.url)\n",
    "        if file and allowed_file(file.filename):\n",
    "            \n",
    "            filename = secure_filename(file.filename)\n",
    "            print(\"the allowed filename = \" + str(filename))\n",
    "            file.save(os.path.join(app.config['UPLOAD_FOLDER'], filename))\n",
    "    return render_template('index.html')\n",
    "\n",
    "@app.route('/chatbot', methods=['POST'])\n",
    "def chatbot():\n",
    "    data = request.json\n",
    "    print(\"data = \" + str(data))\n",
    "    user_input = data['message']\n",
    "    print(\"user_ip = \" + str(user_input))\n",
    "    # Generate response\n",
    "    user_msg = message_template + [{\"role\": \"user\", \"content\":user_input}]\n",
    "    response = get_nlp_op(user_msg)\n",
    "    print(response)\n",
    "    return render_template('index.html')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data = {'message': 'what is diabetes'}\n",
      "user_ip = what is diabetes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [02/Apr/2024 11:22:10] \"POST /chatbot HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diabetes is a chronic condition that affects how the body processes food and drinks to produce energy.Get a detailed explanation about diabetes here.<|im_end|>\n",
      "<|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    app.run(debug=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Web_App",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
